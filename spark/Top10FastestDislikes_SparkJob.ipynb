{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workload Summary \n",
    "\n",
    "Find out the top 10 videos with fastest growth\n",
    "of dislikes number between its first and second trending appearances. Here we measure\n",
    "the growth of dislikes number by the gap of dislikes increase and likes increase\n",
    "between the first two trending appearances in the same country.\n",
    "\n",
    "For instance, the dislikes growth of video QwZT7T-TXT0 in US is computed as follows:\n",
    "\n",
    "```\n",
    "(1065772 - 629120) - (1082422 - 835378) = 189608\n",
    "```\n",
    "\n",
    "Where the first component is the increase of dislikes and the second component is\n",
    "the increase of likes between the first and second trending appearances .\n",
    "\n",
    "The result of this workload should show a few details of the top 10 videos, including the\n",
    "video id, category, dislike growth value and country code. Below is a few sample results:\n",
    "\n",
    "```\n",
    "\"BEePFpC9qG8\", 366556, \"Film & Animation\", \"DE\"\n",
    "\"RmZ3DPJQo2k\", 334594, \"Music\", \"KR\"\n",
    "\"1Aoc-cd9eYs\", 192222, \"Entertainment\", \"GB\"\n",
    "\"QwZT7T-TXT0\", 189608, \"Entertainment\", \"US\"\n",
    "\"QwZT7T-TXT0\", 189605, \"Entertainment\", \"GB\"\n",
    "```\n",
    "\n",
    "If a video has changed its category name over time, you can use the category of the\n",
    "first appearance. It is possible to include the same video multiple times in top 10 list if it\n",
    "has large dislikes growth in multiple countries. Video QwZT7T-TXT0 is such an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports \n",
    "import necessary packages and expose pyspark to Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all required import libraries \n",
    "import sys\n",
    "from importlib import reload\n",
    "import findspark\n",
    "import filterHelpers as helpers\n",
    "findspark.init()\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'filterHelpers' from '/Users/nagibshah/dev/COMP5349_MRandSpark/spark/filterHelpers.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(helpers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spark context and set paths \n",
    "create the spark context and set the input/output paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"Top 10 Fastest Video Dislikes Trend\")\n",
    "\n",
    "#You can change the input path pointing to your own HDFS\n",
    "#If spark is able to read hadoop configuration, you can use relative path\n",
    "input_path = '../data/' # local file system relative path \n",
    "\n",
    "#Relative path is used to specify the output directory\n",
    "#The relative path is always relative to your home directory in HDFS: /user/<yourUserName>\n",
    "output_path = '../data/top10VideosOut'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoData = sc.textFile(input_path + \"AllVideos_short.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the filtering and processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "videoStats = videoData.map(helpers.extractMovieRecord).filter(lambda x: x)\n",
    "\n",
    "# group by key & filter by country \n",
    "groupedTrends = videoStats.groupByKey().mapValues(helpers.mapFirstTwoRecords)\n",
    "# unpack the values in the rdd (K, [V,V]) > (K, V) & sort by the key \n",
    "videoTrends = groupedTrends.flatMap(lambda x: [(x[0], y) for y in x[1]]).sortByKey()\n",
    "# reduce by key to sum the likes and dislikes \n",
    "videoTrendsDislikes = videoTrends.reduceByKey(helpers.reduceLikesDislikesGrowth).map(helpers.mapDislikesTrend)\n",
    "# sort by the trend value in descending order \n",
    "videoTrendsSorted = videoTrendsDislikes.sortBy(lambda x: x[1],ascending=False)\n",
    "print(type(videoTrendsSorted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial map size: 3215232\n",
      "post grouping and map - 2 records per video per region: 1784056\n",
      "Total number of records ungrouped: 373623\n",
      "Total number of unique video id (post grouping): 207142\n"
     ]
    }
   ],
   "source": [
    "print(\"initial map size: {}\".format(sys.getsizeof(videoStats.collect())))\n",
    "print(\"post grouping and map - 2 records per video per region: {}\"\n",
    "      .format(sys.getsizeof(groupedTrends.collect())))\n",
    "\n",
    "print(\"Total number of records ungrouped: {}\".format(videoStats.count()))\n",
    "print(\"Total number of unique video id (post grouping): {}\".format(groupedTrends.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('SbOwzAl9ZfQ', 'MX'), [['Entertainment', 4182, 361], ['Entertainment', 5891, 553]]), (('_OXDcGPVAa4', 'MX'), [['Howto & Style', 57781, 681], ['Howto & Style', 93269, 1792]]), (('Q9kK6NWZR1U', 'MX'), [['Music', 506, 67]]), (('rZZEeeAVgog', 'MX'), [['Comedy', 23279, 270]]), (('kTT472QeJGg', 'MX'), [['People & Blogs', 17070, 7718]]), (('yhdI98_O-Xc', 'MX'), [['People & Blogs', 13293, 216]]), (('7jmJtdqI6YE', 'MX'), [['Entertainment', 194, 41], ['Entertainment', 347, 78]]), (('OFXU_vrye9w', 'MX'), [['Comedy', 705, 199]]), (('WflHonz04Uc', 'MX'), [['Entertainment', 20, 53]]), (('d1oYTRYmNHs', 'MX'), [['Comedy', 28782, 1770]])]\n",
      "\n",
      "\n",
      "\n",
      "[(('--1skHapGUc', 'MX'), ['Entertainment', 483, 77]), (('--2K8l6BWfw', 'FR'), ['Pets & Animals', 694, 4]), (('--45ws7CEN0', 'CA'), ['Gaming', 3837, 516]), (('--45ws7CEN0', 'MX'), ['Gaming', 3837, 516]), (('--45ws7CEN0', 'RU'), ['Gaming', 3837, 516]), (('--6vcer7XYQ', 'MX'), ['Entertainment', 148, 12]), (('--6vcer7XYQ', 'MX'), ['Entertainment', 1626, 218]), (('--728h8mnDY', 'FR'), ['Howto & Style', 2108, 42]), (('--728h8mnDY', 'FR'), ['Howto & Style', 2573, 51]), (('--7vNbh4UNA', 'CA'), ['News & Politics', 52114, 1284])]\n"
     ]
    }
   ],
   "source": [
    "# print samples \n",
    "print(groupedTrends.take(10))\n",
    "print(\"\\n\")\n",
    "print(videoTrends.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('BEePFpC9qG8', 366556, 'Film & Animation', 'DE'), ('RmZ3DPJQo2k', 334594, 'Music', 'KR'), ('1Aoc-cd9eYs', 192222, 'Entertainment', 'GB'), ('QwZT7T-TXT0', 189608, 'Entertainment', 'US'), ('QwZT7T-TXT0', 189605, 'Entertainment', 'GB'), ('PfLCyR6Efvw', 106418, 'Music', 'GB'), ('8d_202l55LU', 105839, 'News & Politics', 'DE'), ('ZGEoqPpJQLE', 98934, 'Music', 'DE'), ('ZGEoqPpJQLE', 98930, 'Music', 'RU'), ('84LBjXaeKk4', 93961, 'Entertainment', 'FR')]\n"
     ]
    }
   ],
   "source": [
    "# print the top 10\n",
    "top10ControversialVideos = sc.parallelize(videoTrendsSorted.take(10))\n",
    "print(top10ControversialVideos.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output \n",
    "# coalesce to create a single partition out of the top 10 entries\n",
    "top10ControversialVideos.coalesce(1,False).saveAsTextFile(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final step - safely stop the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the spark context \n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
