{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workload Summary \n",
    "\n",
    "Find out the top 10 videos with fastest growth\n",
    "of dislikes number between its first and second trending appearances. Here we measure\n",
    "the growth of dislikes number by the gap of dislikes increase and likes increase\n",
    "between the first two trending appearances in the same country.\n",
    "\n",
    "For instance, the dislikes growth of video QwZT7T-TXT0 in US is computed as follows:\n",
    "\n",
    "```\n",
    "(1065772 - 629120) - (1082422 - 835378) = 189608\n",
    "```\n",
    "\n",
    "Where the first component is the increase of dislikes and the second component is\n",
    "the increase of likes between the first and second trending appearances .\n",
    "\n",
    "The result of this workload should show a few details of the top 10 videos, including the\n",
    "video id, category, dislike growth value and country code. Below is a few sample results:\n",
    "\n",
    "```\n",
    "\"BEePFpC9qG8\", 366556, \"Film & Animation\", \"DE\"\n",
    "\"RmZ3DPJQo2k\", 334594, \"Music\", \"KR\"\n",
    "\"1Aoc-cd9eYs\", 192222, \"Entertainment\", \"GB\"\n",
    "\"QwZT7T-TXT0\", 189608, \"Entertainment\", \"US\"\n",
    "\"QwZT7T-TXT0\", 189605, \"Entertainment\", \"GB\"\n",
    "```\n",
    "\n",
    "If a video has changed its category name over time, you can use the category of the\n",
    "first appearance. It is possible to include the same video multiple times in top 10 list if it\n",
    "has large dislikes growth in multiple countries. Video QwZT7T-TXT0 is such an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports \n",
    "import necessary packages and expose pyspark to Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all required import libraries \n",
    "import findspark\n",
    "# from ml_utils import *\n",
    "findspark.init()\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spark context and set paths \n",
    "create the spark context and set the input/output paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"Top 10 Fastest Video Dislikes Trend\")\n",
    "\n",
    "#You can change the input path pointing to your own HDFS\n",
    "#If spark is able to read hadoop configuration, you can use relative path\n",
    "input_path = '../data/' # local file system relative path \n",
    "\n",
    "#Relative path is used to specify the output directory\n",
    "#The relative path is always relative to your home directory in HDFS: /user/<yourUserName>\n",
    "output_path = 'top10VideosOut'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoData = sc.textFile(input_path + \"AllVideos_short.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the filtering and processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "print(type(videoData))\n",
    "\n",
    "#movieRatings = ratings.map(extractRating)\n",
    "#movieGenre = movieData.flatMap(pairMovieToGenre) # we use flatMap as there are multiple genre per movie\n",
    "\n",
    "#genreRatings = movieGenre.join(movieRatings).values()\n",
    "#genreRatingsAverage = genreRatings.aggregateByKey((0.0,0), mergeRating, mergeCombiners, 1).map(mapAverageRating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output \n",
    "#genreRatingsAverage.saveAsTextFile(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final step - safely stop the spark context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the spark context \n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
